{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook is used to analyse collision warning results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "font = {'family' : 'Arial',\n",
    "        'size'   : 9}\n",
    "plt.rc('font', **font)\n",
    "plt.rcParams['mathtext.fontset'] = 'stix' #dejavuserif\n",
    "sys.path.append('../../')\n",
    "from Demonstration.demonstration_utils import *\n",
    "\n",
    "def to_grayscale(fig):\n",
    "    fig.canvas.draw()\n",
    "    img = np.array(fig.canvas.renderer.buffer_rgba())\n",
    "    grayscale_img = np.dot(img[..., :3], [0.2989, 0.5870, 0.1140])\n",
    "    fig_gray, ax_gray = plt.subplots(figsize=(fig.get_size_inches()), dpi=fig.dpi)\n",
    "    ax_gray.imshow(grayscale_img, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\n",
    "    ax_gray.axis('off')  # Turn off the axis\n",
    "    ax_gray.set_title('Grayscale plot')\n",
    "\n",
    "path_matched_100Car = '../../../Process_100Car/MatchedEvents/'  # Path to processed data outside the repository\n",
    "path_processed = '../../Data/ProcessedData/100Car/'\n",
    "path_input = '../../Data/InputData/'\n",
    "path_output = '../../Data/OutputData/'\n",
    "fig_path = r'C:/SURFdrive/PhD progress/PhDResearch/4_Conflict/AMAR/Figures/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Originally matched events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_crashes = pd.read_csv(path_matched_100Car+'HundredCar_metadata_Crashes.csv')\n",
    "meta_crashes.groupby('target').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_nearcrashes = pd.read_csv(path_matched_100Car+'HundredCar_metadata_NearCrashes.csv')\n",
    "meta_nearcrashes.groupby('target').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.read_hdf(path_input + '100Car/HundredCar_Crashes.h5', key='data')\n",
    "meta = pd.read_csv(path_input + '100Car/HundredCar_metadata_Crashes.csv').set_index('webfileid')\n",
    "print('Crash targets: ', meta.groupby('target').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.read_hdf(path_input + '100Car/HundredCar_NearCrashes.h5', key='data')\n",
    "meta = pd.read_csv(path_input + '100Car/HundredCar_metadata_NearCrashes.csv').set_index('webfileid')\n",
    "print('Crash targets: ', meta.groupby('target').size().sort_values(ascending=False))\n",
    "print('Near-crash with veh in adjacent lane: ', meta[meta['target']=='vehicle in adjacent lane'].index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warning evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttc_warning, statistics_ttc, optimal_ttc = read_data('TTC', path_output)\n",
    "drac_warning, statistics_drac, optimal_drac = read_data('DRAC', path_output)\n",
    "psd_warning, statistics_psd, optimal_psd = read_data('PSD', path_output)\n",
    "unified_warning, statistics_unified, optimal_unified = read_data('Unified', path_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttc_selected = read_selected('TTC', path_output)\n",
    "drac_selected = read_selected('DRAC', path_output)\n",
    "psd_selected = read_selected('PSD', path_output)\n",
    "unified_selected = read_selected('Unified', path_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_warning([statistics_ttc, optimal_ttc, ttc_selected],\n",
    "                   [statistics_drac, optimal_drac, drac_selected],\n",
    "                   [statistics_psd, optimal_psd, psd_selected],\n",
    "                   [statistics_unified, optimal_unified, unified_selected])\n",
    "to_grayscale(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(fig_path + 'warning_evaluation.pdf', bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_unified[(statistics_unified['true positive rate']>0.9)&(statistics_unified['false positive rate']<0.05)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for unified, tof_unified in zip([optimal_unified['true warning'], ~optimal_unified['true warning']], ['unified true', 'unified false']):\n",
    "    for ttc, tof_ttc in zip([optimal_ttc['true warning'], ~optimal_ttc['true warning']], ['ttc true', 'ttc false']):\n",
    "        for drac, tof_drac in zip([optimal_drac['true warning'], ~optimal_drac['true warning']], ['drac true', 'drac false']):\n",
    "            statistics = optimal_ttc[ttc&drac&unified]\n",
    "            print(tof_unified, ',', tof_ttc, ',', tof_drac, ',', len(statistics), ',', statistics.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('unified false warning:', optimal_unified[optimal_unified['false warning']].index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conflict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
